#define memoryAlloc(s uint) ptr
#define memoryRealloc(o ptr, s uint) ptr
#define memoryAllocSTR(s uint) str

#include "thread.bah"

#debug {
    #define getTimeUnix() int
}

GC_min_collect = 256000000
VERBOSE_GC = false

const GC_min_ptr = 16777216
const GC_max_ptr = 281474976710656

#define qsort(arr ptr, elementCount uint, elementSize uint, fn ptr)
#define itoa(i int) str
#define syscall(nb int) int

#define printInt(i int)
#define backtrace(l uint)


struct BAH_GC_ptr {
    size: uint
    p: uint
    marked: bool
    notScannable: bool
}

struct BAH_GC_thread {
    t: pthread_t
    sysid: uint
    regs: buffer:184

    next: BAH_GC_thread*

    clean() {
        free(this)
    }

}

struct BAH_GC_page {
    page: uint

    next: BAH_GC_page*
}


struct BAH_GC_channelNode {
    data: BAH_GC_ptr*
    next: BAH_GC_channelNode*
}

// struct BAH_GC_channel {
//     m_mut: pthread_mutex_t

//     w_cond: pthread_cond_t
//     r_cond: pthread_cond_t

//     w_waitting: int = 0
//     r_waitting: int = 0

//     queue: BAH_GC_channelNode*

//     //To send data to the channel.
//     send(data BAH_GC_ptr*) {
//         pthread_mutex_lock(&this.m_mut)
//         newNode = <BAH_GC_channelNode*>malloc(sizeof(BAH_GC_channelNode))
//         newNode.next = this.queue
//         newNode.data = data
//         this.queue = newNode
//         if this.r_waitting > 0 {
//             pthread_cond_signal(&this.r_cond)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//     }

//     //To receive data (a pointer) from the channel.
//     //Note that this is a blockant operation.
//     //If no data is available the function will pause the execution of the current thread.
//     receive() BAH_GC_ptr* {
//         pthread_mutex_lock(&this.m_mut)
//         for this.queue == null {
//             this.r_waitting++
//             pthread_cond_wait(&this.r_cond, &this.m_mut)
//             this.r_waitting--
//         }

//         node = this.queue
//         this.queue = node.next
//         data = node.data
//         free(node)
//         if this.w_waitting > 0 {
//             pthread_cond_signal(&this.w_cond)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//         return data
//     }

//     waitForEmpty() {
//         pthread_mutex_lock(&this.m_mut)
//         for this.queue != null {
//             pthread_cond_wait(&this.r_cond, &this.m_mut)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//     }

//     //To destroy a channel after using it. Not destroying it could result in memory leaks.
//     destroy() {
//         pthread_mutex_destroy(&this.m_mut)
//         pthread_cond_destroy(&this.w_cond)
//         pthread_cond_destroy(&this.r_cond)
//     }

//     _init() {
//         pthread_mutex_init(&this.m_mut, 0)
//         pthread_cond_init(&this.w_cond, null)
//         pthread_cond_init(&this.r_cond, null)
//     }

// }

struct BAH_GC_state_tag {
    heapSize: uint
    nextCollect: uint = GC_min_collect

    list: BAH_GC_ptr*
    listLength: uint
    listRealLength: uint

    pages: BAH_GC_page*

    stackBase: uint
    threads: BAH_GC_thread*
    scanThreads: BAH_GC_thread*
    mainThread: int

    mut: pthread_mutex_t*
    cond: pthread_cond_t*
    // scanMut: pthread_mutex_t*

    countMut: pthread_mutex_t*
    count: uint
    collected: bool
    needsFinalizer: bool
    areThreadsFree: bool

    // scanChannel: BAH_GC_channel

    overflowQueue: BAH_GC_channelNode*

    isPointerInBounds(p uint) bool {
        if p < GC_min_ptr {
            return false
        }
        if p > GC_max_ptr {
            return false
        }
        pageNb = <uint32>(p >> 24)

        currPage = this.pages
        for currPage != null, currPage = currPage.next {
            if pageNb == currPage.page {
                return true
            }
        }

        return false
    }

    updatePagesBounds(p uint) {
        pageNb = <uint32>(p >> 24)
        
        currPage = this.pages
        for currPage != null, currPage = currPage.next {
            if pageNb == currPage.page {
                break
            }
        }

        if currPage == null {
            currPage = malloc(sizeof(BAH_GC_page))
            currPage.page = pageNb
            currPage.next = this.pages
            this.pages = currPage
        }
    }

    allocate(s uint, notScannable bool) uint {
        p = <uint>malloc(s)

        if p == 0 {
            panic("GC: could not allocate memory.")
        }


        this.heapSize += s

        if this.listLength == this.listRealLength {
            this.listRealLength *= 2
            this.list = realloc(this.list, sizeof(BAH_GC_ptr) * this.listRealLength)
            sizeDiff = (this.listRealLength / 2) * sizeof(BAH_GC_ptr)
            memset(<ptr>(<uint>this.list + sizeDiff), 0, sizeDiff)
        }

        index BAH_GC_ptr*

        i = this.listLength
        for i < this.listRealLength, i++ {
            index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))
            if index.p == 0 {
                break
            }
        }

        if i == this.listRealLength {
            i = this.listLength-1
            for i != -1, i-- {
                index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))
                if index.p == 0 {
                    break
                }
            }
        }

        if i == -1 {
            panic("GC: fatal error")
        }

        this.listLength++

        index.size = s
        index.p = p
        index.notScannable = notScannable

        this.updatePagesBounds(p)

        return p
    }

    find(p uint) BAH_GC_ptr* {
        min = 0
        l = this.listLength
        i = min + l / 2
        curr = l / 4

        lastAdd = true
        atomic = false

        for i >= min && i < l, curr /= 2 {
            index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))

            if curr == 0 {
                curr = 1
                atomic = true
            }

            if index.p > p {
                if atomic && lastAdd == false {
                    break
                }
                i += curr
                lastAdd = true
            } else if index.p < p {
                if atomic && lastAdd {
                    break
                }
                i -= curr
                lastAdd = false
            } else {
                return index
            }
        }

        return null
    }
}


GC_sort_pointers(a BAH_GC_ptr*, b BAH_GC_ptr*) int {
    if a.p < b.p {
        return 1
    }

    return -1
}

BAH_GC_state BAH_GC_state_tag

GC_setHeapSize(size uint) {
    GC_min_collect = size
    BAH_GC_state.nextCollect = size
}

#define GC_scan(from uint, to uint, alignment uint)
#define real_pthread_exit(val ptr)

GC_thread_wrapper(args ptr*) {

    t = <BAH_GC_thread*>*args

    pthread_mutex_lock(BAH_GC_state.mut)
    t.sysid = syscall(__NR_gettid)
    pthread_mutex_unlock(BAH_GC_state.mut)

    fn function(ptr) = *(<ptr*>(<uint>args + 16))

    fnArg = *(<ptr*>(<uint>args + sizeof(ptr)))
    free(args)

    fn(fnArg)

    //remove the thread from the linked list
    pthread_mutex_lock(BAH_GC_state.mut)
    if t == BAH_GC_state.threads {
        BAH_GC_state.threads = t.next
        t.clean()
    } else {
        ct = BAH_GC_state.threads; for ct != null, ct = ct.next {
            if ct.next == t {
                ct.next = t.next
                t.clean()
                break
            }
        }
    }
    pthread_mutex_unlock(BAH_GC_state.mut)

    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.count--
    pthread_cond_signal(BAH_GC_state.cond)
    pthread_mutex_unlock(BAH_GC_state.countMut)
}

GC_removeCurrentThread(val ptr) {
    //remove the thread from the linked list
    callerId = syscall(__NR_gettid)

    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.threads.sysid == callerId {
        t = BAH_GC_state.threads
        BAH_GC_state.threads = BAH_GC_state.threads.next
        t.clean()
    } else {
        currT = BAH_GC_state.threads
        for currT != null, currT = currT.next {
            if currT.next.sysid == callerId {
                t = currT.next
                currT.next = t.next
                t.clean()
                break
            }
        }
    }

    pthread_mutex_unlock(BAH_GC_state.mut)
    
    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.count--
    pthread_cond_signal(BAH_GC_state.cond)
    pthread_mutex_unlock(BAH_GC_state.countMut)

    real_pthread_exit(val)

}

#define GC_collect_out_of_context(regs ptr)

GC_thread_sig_handler(sig int, info ptr, ctx ptr) {
    callerId = syscall(__NR_gettid)

    if callerId == BAH_GC_state.mainThread {
        GC_collect_out_of_context(<ptr>(<uint>ctx + 40))
        return
    }

    t = BAH_GC_state.threads
    for t != null, t = t.next {
        if t.sysid == callerId {
            break
        }
    }
    memcpy(<ptr>t.regs, <ptr>(<uint>ctx + 40), 184)

    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.count--
    pthread_cond_signal(BAH_GC_state.cond)
    pthread_mutex_unlock(BAH_GC_state.countMut)


    pthread_mutex_lock(BAH_GC_state.countMut)
    for BAH_GC_state.areThreadsFree == false {
        pthread_cond_wait(BAH_GC_state.cond, BAH_GC_state.countMut)
    }
    pthread_mutex_unlock(BAH_GC_state.countMut)

    // pthread_mutex_lock(BAH_GC_state.mut)
    // pthread_mutex_unlock(BAH_GC_state.mut)
}

GC_thread_create(id pthread_t*, attr pthread_attr_t*, func ptr, args ptr) int32 {
    t = <BAH_GC_thread*>malloc(sizeof(BAH_GC_thread))
    if id == null {
        id = &t.t
    }

    pthread_mutex_lock(BAH_GC_state.mut)
    t.next = BAH_GC_state.threads
    BAH_GC_state.threads = t
    pthread_mutex_unlock(BAH_GC_state.mut)

    agrsWrapper = <ptr*>malloc(sizeof(ptr) * 3)
    
    argsW = <ptr*>(<uint>agrsWrapper + sizeof(ptr))
    fnW = <ptr*>(<uint>agrsWrapper + 2 * sizeof(ptr))

    *agrsWrapper = t
    *argsW = args
    *fnW = func

    errNo = pthread_create(id, attr, GC_thread_wrapper, agrsWrapper)


    t.t = *id

    return errNo
}

GC_thread_create_detached(id pthread_t*, attr pthread_attr_t*, func ptr, args ptr) int32 {
    t = <BAH_GC_thread*>malloc(sizeof(BAH_GC_thread))
    if id == null {
        id = &t.t
    }

    pthread_mutex_lock(BAH_GC_state.mut)
    t.next = BAH_GC_state.threads
    BAH_GC_state.threads = t
    pthread_mutex_unlock(BAH_GC_state.mut)

    agrsWrapper = <ptr*>malloc(sizeof(ptr) * 3)
    
    argsW = <ptr*>(<uint>agrsWrapper + sizeof(ptr))
    fnW = <ptr*>(<uint>agrsWrapper + 2 * sizeof(ptr))

    *agrsWrapper = t
    *argsW = args
    *fnW = func

    realAttr pthread_attr_t

    if attr != null {
        realAttr = *attr
    } else {
        pthread_attr_init(&realAttr)
    }

    pthread_attr_setdetachstate(&realAttr, 1)

    errNo = pthread_create(id, &realAttr, GC_thread_wrapper, agrsWrapper)

    pthread_attr_destroy(&realAttr)

    t.t = *id

    return errNo
}


GC_thread_join(id pthread_t, ret ptr) int32 {
    return pthread_join(id, ret)
}

GC_setStackBase() {
    BAH_GC_state.stackBase = <uint>$rsp
}

#define GC_thread_worker()

GC_init() {
    BAH_GC_state.mainThread = syscall(__NR_gettid)
    BAH_GC_state.nextCollect = GC_min_collect

    action = sigaction {
        sa_handler: GC_thread_sig_handler
        sa_flags: SA_SIGINFO | SA_RESTART
    }
    sigaction(SIGXCPU, &action, null)

    BAH_GC_state.mut = malloc(sizeof(pthread_mutex_t))
    BAH_GC_state.cond = malloc(sizeof(pthread_cond_t))
    BAH_GC_state.countMut = malloc(sizeof(pthread_mutex_t))
    // BAH_GC_state.scanMut = malloc(sizeof(pthread_mutex_t))


    pthread_mutex_init(BAH_GC_state.mut, 0)
    pthread_cond_init(BAH_GC_state.cond, null)
    pthread_mutex_init(BAH_GC_state.countMut, 0)
    // pthread_mutex_init(BAH_GC_state.scanMut, 0)

    BAH_GC_state.listLength = 0
    BAH_GC_state.listRealLength = 4096
    s = BAH_GC_state.listRealLength * sizeof(BAH_GC_ptr)
    BAH_GC_state.list = malloc(s)
    memset(BAH_GC_state.list, 0, s)

    // BAH_GC_state.scanChannel = BAH_GC_channel{}

    // i=0; for i < 4, i++ {
    //     st = <BAH_GC_thread*>malloc(sizeof(BAH_GC_thread))
    //     pthread_create(&st.t, null, GC_thread_worker, null)
    //     st.next = BAH_GC_state.scanThreads
    //     BAH_GC_state.scanThreads = st
    // }
}

#init GC_setStackBase()
#init GC_init()


GC_markPtr(p uint) {
    if p == 0 {
        return
    }

    if BAH_GC_state.isPointerInBounds(p) == false || p == <uint>BAH_GC_state.list {
        return
    }

    gcPtr = BAH_GC_state.find(p)

    if gcPtr == null {
        return
    }

    if gcPtr.marked {
        return
    }

    gcPtr.marked = true

    if gcPtr.notScannable == false {
        if BAH_GC_state.stackBase - <uint>$rbp >= 6000000 {
            overflowNode = <BAH_GC_channelNode*>malloc(sizeof(BAH_GC_channelNode))
            overflowNode.data = gcPtr
            overflowNode.next = BAH_GC_state.overflowQueue
            BAH_GC_state.overflowQueue = overflowNode
            return
        }
        GC_scan(p, p + gcPtr.size - 7, 1)
    }
}


GC_scan(p uint, to uint, alignment uint) {
    // p = from
    // if from > to || to - from < alignment {
    //     return
    // }
    // printInt(to - from)
    for p < to, p = p + alignment {
        GC_markPtr(*<uint*>p)
    }
}

GC_scanReversed(p uint, to uint, alignment uint) {
    // p = from
    // if from < to || from - to < alignment {
    //     return
    // }
    for p > to, p = p - alignment {
        GC_markPtr(*<uint*>p)
    }
}

GC_stopWorld() uint {
    t = BAH_GC_state.threads
    callerId = syscall(__NR_gettid)
    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.count = 0
    nb = 0
    for t != null, t = t.next {
        if t.sysid == callerId {
            continue
        }
        if sigqueue(t.sysid, SIGXCPU, t) == 0 {
            BAH_GC_state.count++
        }
        nb++
    }
    pthread_mutex_unlock(BAH_GC_state.countMut)
    return nb
}

// GC_thread_worker() {
//     for 1==1 {
//         gcPtr = BAH_GC_state.scanChannel.receive()
//         GC_scan(gcPtr.p, gcPtr.p + gcPtr.size - 7, 1)
//     }
// }

GC_collect_out_of_context(regs ptr) {
    pthread_mutex_lock(BAH_GC_state.mut)

    #debug {
        if VERBOSE_GC {
            puts("[GC] Collecting (out of context).")
        }
        scanStart = getTimeUnix()
    }

    BAH_GC_state.areThreadsFree = false
    GC_stopWorld()
    qsort(BAH_GC_state.list, BAH_GC_state.listRealLength, sizeof(BAH_GC_ptr), GC_sort_pointers)

    //check registers
    GC_scan(<uint>regs, <uint>regs + 184, 8)
    currBasePointer = *<uint*>(<uint>regs + 80)

    //check .data and .bss
    dataStart = <uint>$data
    bssStart = <uint>$bss
    bssEnd = <uint>$end

    GC_scan(dataStart, bssStart, 1)
    GC_scan(bssStart, bssEnd, 1)


    //check stack
    GC_scanReversed(BAH_GC_state.stackBase, currBasePointer + 16, 8)

    pthread_mutex_lock(BAH_GC_state.countMut)
    for BAH_GC_state.count != 0 {
        pthread_cond_wait(BAH_GC_state.cond, BAH_GC_state.countMut)
    }
    pthread_mutex_unlock(BAH_GC_state.countMut)

    //scan threads stacks
    callerId = syscall(__NR_gettid)
    BAH_GC_state.count = 0
    ct = BAH_GC_state.threads
    for ct != null, ct = ct.next {
        s uint = 0
        addr uint = 0
        attr pthread_attr_t
        pthread_getattr_np(ct.t, &attr)
        pthread_attr_getstack(&attr, &addr, &s)
        pthread_attr_destroy(&attr)
        GC_scanReversed(<uint>addr + s - 8, addr, 8)
        GC_scan(<uint>ct.regs, <uint>ct.regs + 184, 8)
    }

    BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
    if BAH_GC_state.nextCollect < GC_min_collect {
        BAH_GC_state.nextCollect = GC_min_collect
    }

    BAH_GC_state.needsFinalizer = true

    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.areThreadsFree = true
    pthread_cond_signal(BAH_GC_state.cond)
    pthread_mutex_unlock(BAH_GC_state.countMut)

    pthread_mutex_unlock(BAH_GC_state.mut)
}

//this calls free() that is not signal safe.
//calling this from a signal handler (GC_collect_out_of_context) could cause
//a dead lock because a c lib could use malloc when the world stops -> free could not
//acquire lock until paused thread resumes but thrad would not resume until collection is finished

//TODO: when stack overflows in GC_markPtr(), calls to malloc() and free() are made
//      this is the same problem but it is quite rare...

GC_finalize_out_of_context_collect() {
    BAH_GC_state.needsFinalizer = false
    freed=0
    alive=0

    additional=0
    for BAH_GC_state.overflowQueue != null {
        currQueue = BAH_GC_state.overflowQueue
        BAH_GC_state.overflowQueue = null
        for currQueue != null {
            GC_scan(currQueue.data.p, currQueue.data.p + currQueue.data.size - 7, 1)
            prevQueue = currQueue
            currQueue = currQueue.next
            free(prevQueue)
            additional++
        }
    }

    l = BAH_GC_state.listLength
    i=0; for i < l, i++ {
        index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
        if index.p == 0 {
            continue
        }

        if index.marked == false {
            freed++
            free(<ptr>index.p)
            index.p = 0
            BAH_GC_state.heapSize -= index.size
            BAH_GC_state.listLength--
            continue
        }
        alive++

        index.marked = false
    }

    qsort(BAH_GC_state.list, l, sizeof(BAH_GC_ptr), GC_sort_pointers)

    #debug {
        if VERBOSE_GC {

            nbPages = 0
            currPage = BAH_GC_state.pages
            for currPage != null, currPage = currPage.next {
                nbPages++
            }

            puts("===COLLECT RESULTS===")
            puts("freed: ")
            printInt(freed)
            puts("still allive: ")
            printInt(alive)
            puts("heap size:")
            printInt(BAH_GC_state.heapSize)
            puts("nb pages:")
            printInt(nbPages)
            puts("=====================")
        }
    }
}

GC_collect() {
    //save registers
    ordi = <uint>$rdi
    orsi = <uint>$rsi
    ordx = <uint>$rdx
    orcx = <uint>$rcx
    or8 = <uint>$r8
    or9 = <uint>$r9
    or10 = <uint>$r10
    or11 = <uint>$r11
    or12 = <uint>$r12
    or13 = <uint>$r13
    or14 = <uint>$r14
    or15 = <uint>$r15
    orax = <uint>$rax
    orbx = <uint>$rbx

    BAH_GC_state.collected = false

    currBasePointer = <uint>$rbp + 8

    if syscall(__NR_gettid) != BAH_GC_state.mainThread {
        //TODO: siqueue main thread and call collect there
        sigqueue(BAH_GC_state.mainThread, SIGXCPU, null)
        return  //only the main thread can pause the world
    }

    qsort(BAH_GC_state.list, BAH_GC_state.listRealLength, sizeof(BAH_GC_ptr), GC_sort_pointers)

    #debug {
        if VERBOSE_GC {
            puts("[GC] Collecting.")
        }
        scanStart = getTimeUnix()
    }

    BAH_GC_state.areThreadsFree = false
    GC_stopWorld()

    //check registers
    GC_markPtr(ordi)
    GC_markPtr(orsi)
    GC_markPtr(ordx)
    GC_markPtr(orcx)
    GC_markPtr(or8)
    GC_markPtr(or9)
    GC_markPtr(or10)
    GC_markPtr(or11)
    GC_markPtr(or12)
    GC_markPtr(or13)
    GC_markPtr(or14)
    GC_markPtr(or15)
    GC_markPtr(orax)
    GC_markPtr(orbx)

    //check .data and .bss
    dataStart = <uint>$data
    bssStart = <uint>$bss
    bssEnd = <uint>$end

    GC_scan(dataStart, bssStart, 1)
    GC_scan(bssStart, bssEnd, 1)


    //check stack
    GC_scanReversed(BAH_GC_state.stackBase, currBasePointer, 8)
    

    pthread_mutex_lock(BAH_GC_state.countMut)
    for BAH_GC_state.count != 0 {
        pthread_cond_wait(BAH_GC_state.cond, BAH_GC_state.countMut)
    }
    pthread_mutex_unlock(BAH_GC_state.countMut)

    //scan threads stacks
    callerId = syscall(__NR_gettid)
    BAH_GC_state.count = 0
    ct = BAH_GC_state.threads
    for ct != null, ct = ct.next {
        s uint = 0
        addr uint = 0
        attr pthread_attr_t
        pthread_getattr_np(ct.t, &attr)
        pthread_attr_getstack(&attr, &addr, &s)
        pthread_attr_destroy(&attr)
        GC_scanReversed(<uint>addr + s - 8, addr, 8)
        GC_scan(<uint>ct.regs, <uint>ct.regs + 184, 8)
    }

    freed=0
    alive=0

    additional=0
    for BAH_GC_state.overflowQueue != null {
        currQueue = BAH_GC_state.overflowQueue
        BAH_GC_state.overflowQueue = null
        for currQueue != null {
            GC_scan(currQueue.data.p, currQueue.data.p + currQueue.data.size - 7, 1)
            prevQueue = currQueue
            currQueue = currQueue.next
            free(prevQueue)
            additional++
        }
    }

    l = BAH_GC_state.listLength
    i=0; for i < l, i++ {
        index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
        if index.p == 0 {
            continue
        }

        if index.marked == false {
            freed++
            free(<ptr>index.p)
            index.p = 0
            BAH_GC_state.heapSize -= index.size
            BAH_GC_state.listLength--
            continue
        }
        alive++

        index.marked = false
    }

    qsort(BAH_GC_state.list, l, sizeof(BAH_GC_ptr), GC_sort_pointers)

    #debug {
        if VERBOSE_GC {

            nbPages = 0
            currPage = BAH_GC_state.pages
            for currPage != null, currPage = currPage.next {
                nbPages++
            }

            puts("===COLLECT RESULTS===")
            puts("freed: ")
            printInt(freed)
            puts("still allive: ")
            printInt(alive)
            puts("heap size:")
            printInt(BAH_GC_state.heapSize)
            puts("nb pages:")
            printInt(nbPages)
            puts("took (ms):")
            printInt((getTimeUnix() - scanStart) / 1000000)
            puts("=====================")
        }
    }

    pthread_mutex_lock(BAH_GC_state.countMut)
    BAH_GC_state.areThreadsFree = true
    pthread_cond_broadcast(BAH_GC_state.cond)
    pthread_mutex_unlock(BAH_GC_state.countMut)
}

memoryAlloc(s uint) ptr {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.needsFinalizer {
        GC_finalize_out_of_context_collect()
    }
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, false)
    memset(<ptr>r, 0, s)

    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}

memoryAlloc_NZ(s uint) ptr {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.needsFinalizer {
        GC_finalize_out_of_context_collect()
    }
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, false)

    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}

memoryRealloc(o ptr, s uint) ptr {
    if o == null {
        return memoryAlloc(s)
    }

    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.needsFinalizer {
        GC_finalize_out_of_context_collect()
    }
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }

    

    r = <uint>realloc(o, s)

    if r == 0 {
        panic("GC: could not reallocate memory.")
    }

    index BAH_GC_ptr*
    i=BAH_GC_state.listRealLength; for i != -1, i-- {
        index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
        if index.p == <uint>o {
            break
        }

    }

    if i == BAH_GC_state.listRealLength {
        panic("GC: fatal error doing reallocation")
    }

    memset(<ptr>(<uint>r + index.size), 0, s - index.size)

    BAH_GC_state.heapSize += s - index.size
    index.size = s

    if r != <uint>o {
        index.p = r
        BAH_GC_state.updatePagesBounds(r)
    }

    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}


memoryAllocSTR(s uint) str {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.needsFinalizer {
        GC_finalize_out_of_context_collect()
    }
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, true)
    memset(<ptr>r, 0, s)
    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}

memoryAllocSTR_NZ(s uint) str {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.needsFinalizer {
        GC_finalize_out_of_context_collect()
    }
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, true)
    // memset(<ptr>r, 0, s)
    rp = <byte*>(<uint>r + s - 1)
    *rp = <byte>0
    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}