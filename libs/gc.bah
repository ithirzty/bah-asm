#define memoryAlloc(s uint) ptr
#define memoryRealloc(o ptr, s uint) ptr
#define memoryAllocSTR(s uint) str

#include "thread.bah"

const GC_min_collect = 256000000

#define qsort(arr ptr, elementCount uint, elementSize uint, fn ptr)
#define itoa(i int) str
#define syscall(nb int) int

test = 23


#define intToStr(i int) str
#define println(s str)
#define printInt(i int)
#define backtrace(l uint)


struct BAH_GC_ptr {
    size: uint
    p: uint
    marked: bool
    notScannable: bool
}

struct BAH_GC_thread {
    t: pthread_t
    sysid: uint

    next: BAH_GC_thread*

    clean() {
        free(this)
    }

}

struct BAH_GC_page {
    page: uint

    next: BAH_GC_page*
}


struct BAH_GC_channelNode {
    data: BAH_GC_ptr*
    next: BAH_GC_channelNode*
}

// struct BAH_GC_channel {
//     m_mut: pthread_mutex_t

//     w_cond: pthread_cond_t
//     r_cond: pthread_cond_t

//     w_waitting: int = 0
//     r_waitting: int = 0

//     queue: BAH_GC_channelNode*

//     //To send data to the channel.
//     send(data BAH_GC_ptr*) {
//         pthread_mutex_lock(&this.m_mut)
//         newNode = <BAH_GC_channelNode*>malloc(sizeof(BAH_GC_channelNode))
//         newNode.next = this.queue
//         newNode.data = data
//         this.queue = newNode
//         if this.r_waitting > 0 {
//             pthread_cond_signal(&this.r_cond)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//     }

//     //To receive data (a pointer) from the channel.
//     //Note that this is a blockant operation.
//     //If no data is available the function will pause the execution of the current thread.
//     receive() BAH_GC_ptr* {
//         pthread_mutex_lock(&this.m_mut)
//         for this.queue == null {
//             this.r_waitting++
//             pthread_cond_wait(&this.r_cond, &this.m_mut)
//             this.r_waitting--
//         }

//         node = this.queue
//         this.queue = node.next
//         data = node.data
//         free(node)
//         if this.w_waitting > 0 {
//             pthread_cond_signal(&this.w_cond)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//         return data
//     }

//     waitForEmpty() {
//         pthread_mutex_lock(&this.m_mut)
//         for this.queue != null {
//             pthread_cond_wait(&this.r_cond, &this.m_mut)
//         }
//         pthread_mutex_unlock(&this.m_mut)
//     }

//     //To destroy a channel after using it. Not destroying it could result in memory leaks.
//     destroy() {
//         pthread_mutex_destroy(&this.m_mut)
//         pthread_cond_destroy(&this.w_cond)
//         pthread_cond_destroy(&this.r_cond)
//     }

//     _init() {
//         pthread_mutex_init(&this.m_mut, 0)
//         pthread_cond_init(&this.w_cond, null)
//         pthread_cond_init(&this.r_cond, null)
//     }

// }

struct BAH_GC_state_tag {
    heapSize: uint
    nextCollect: uint = GC_min_collect

    list: BAH_GC_ptr*
    listLength: uint
    listRealLength: uint

    pages: BAH_GC_page*

    stackBase: uint
    threads: BAH_GC_thread*
    scanThreads: BAH_GC_thread*
    mainThread: int

    mut: pthread_mutex_t*
    cond: pthread_cond_t*
    // scanMut: pthread_mutex_t*

    // scanChannel: BAH_GC_channel

    overflowQueue: BAH_GC_channelNode*

    isPointerInBounds(p uint) bool {
        // return p >= this.heapMin && p <= this.heapMax
        pageNb = *(<uint32*>(<uint>&p + 3))
        
        currPage = this.pages
        for currPage != null, currPage = currPage.next {
            if pageNb == currPage.page {
                return true
            }
        }

        return false
    }

    updatePagesBounds(p uint) {
        // if p < this.heapMin || this.heapMin == 0 {
        //     this.heapMin = p
        // }

        // if p > this.heapMax {
        //     this.heapMax = p
        // }
        
        pageNb = *(<uint32*>(<uint>&p + 3))
        
        currPage = this.pages
        for currPage != null, currPage = currPage.next {
            if pageNb == currPage.page {
                break
            }
        }

        if currPage == null {
            currPage = malloc(sizeof(BAH_GC_page))
            currPage.page = pageNb
            currPage.next = this.pages
            this.pages = currPage
            // puts("NEW PAGE")
            // printInt(p)
            // printInt(pageNb)
        }
    }

    allocate(s uint, notScannable bool) uint {
        p = <uint>malloc(s)

        if p == 0 {
            panic("GC: could not allocate memory.")
        }


        this.heapSize += s

        if this.listLength == this.listRealLength {
            this.listRealLength *= 2
            this.list = realloc(this.list, sizeof(BAH_GC_ptr) * this.listRealLength)
            sizeDiff = (this.listRealLength / 2) * sizeof(BAH_GC_ptr)
            memset(<ptr>(<uint>this.list + sizeDiff), 0, sizeDiff)
        }

        index BAH_GC_ptr*

        i = this.listLength
        for i < this.listRealLength, i++ {
            index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))
            if index.p == 0 {
                break
            }
        }

        if i == this.listRealLength {
            i = this.listLength-1
            for i != -1, i-- {
                index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))
                if index.p == 0 {
                    break
                }
            }
        }

        if i == -1 {
            panic("GC: fatal error")
        }

        this.listLength++

        index.size = s
        index.p = p
        index.notScannable = notScannable

        this.updatePagesBounds(p)

        return p
    }

    find(p uint) BAH_GC_ptr* {

        min = 0
        l = this.listLength
        i = min + l / 2
        curr = l / 4

        lastAdd = true
        atomic = false

        for i >= min && i < l, curr /= 2 {
            index = <BAH_GC_ptr*>(<uint>this.list + i * sizeof(BAH_GC_ptr))

            if curr == 0 {
                curr = 1
                atomic = true
            }

            if index.p > p {
                if atomic && lastAdd == false {
                    break
                }
                i += curr
                lastAdd = true
            } else if index.p < p {
                if atomic && lastAdd {
                    break
                }
                i -= curr
                lastAdd = false
            } else {
                return index
            }
        }

        return null
    }
}

GC_sort_pointers(a BAH_GC_ptr*, b BAH_GC_ptr*) int {
    if a.p < b.p {
        return 1
    }

    return -1
}

BAH_GC_state BAH_GC_state_tag

#define GC_scan(from uint, to uint, alignment uint)

GC_thread_wrapper(args ptr*) {

    t = <BAH_GC_thread*>*args

    pthread_mutex_lock(BAH_GC_state.mut)
    t.sysid = syscall(__NR_gettid)
    pthread_mutex_unlock(BAH_GC_state.mut)

    fn function(ptr) = *(<ptr*>(<uint>args + 16))

    fn(*(<ptr*>(<uint>args + sizeof(ptr))))

    free(args)

    //remove the thread from the linked list
    pthread_mutex_lock(BAH_GC_state.mut)
    if t == BAH_GC_state.threads {
        BAH_GC_state.threads = t.next
        t.clean()
    } else {
        ct = BAH_GC_state.threads; for ct != null, ct = ct.next {
            if ct.next == t {
                ct.next = t.next
                t.clean()
                break
            }
        }
    }
    pthread_mutex_unlock(BAH_GC_state.mut)

}

GC_thread_sig_handler(sig int) {
    pthread_mutex_lock(BAH_GC_state.mut)
    pthread_mutex_unlock(BAH_GC_state.mut)
}

GC_thread_create(id pthread_t*, attr pthread_attr_t*, func ptr, args ptr) int32 {
    t = <BAH_GC_thread*>malloc(sizeof(BAH_GC_thread))
    if id == null {
        id = &t.t
    }

    pthread_mutex_lock(BAH_GC_state.mut)
    t.next = BAH_GC_state.threads
    BAH_GC_state.threads = t
    pthread_mutex_unlock(BAH_GC_state.mut)

    agrsWrapper = <ptr*>malloc(sizeof(ptr) * 3)
    
    argsW = <ptr*>(<uint>agrsWrapper + sizeof(ptr))
    fnW = <ptr*>(<uint>agrsWrapper + 2 * sizeof(ptr))

    *agrsWrapper = t
    *argsW = args
    *fnW = func

    errNo = pthread_create(id, attr, GC_thread_wrapper, agrsWrapper)


    t.t = *id

    return errNo
}

GC_thread_join(id pthread_t, ret ptr) int32 {
    return pthread_join(id, ret)
}

GC_setStackBase() {
    BAH_GC_state.stackBase = <uint>$rsp
}

#define GC_thread_worker()

GC_init() {
    BAH_GC_state.mainThread = syscall(__NR_gettid)

    action sigaction
    action.sa_flags = 268435460

    memset(&action.sa_mask, 0, sizeof(sigset_t))
    action.sa_handler = GC_thread_sig_handler
    sigaction(SIGXCPU, &action, null)

    BAH_GC_state.mut = malloc(sizeof(pthread_mutex_t))
    BAH_GC_state.cond = malloc(sizeof(pthread_cond_t))
    // BAH_GC_state.scanMut = malloc(sizeof(pthread_mutex_t))


    pthread_mutex_init(BAH_GC_state.mut, 0)
    pthread_cond_init(BAH_GC_state.cond, null)
    // pthread_mutex_init(BAH_GC_state.scanMut, 0)

    BAH_GC_state.listLength = 0
    BAH_GC_state.listRealLength = 4096
    s = BAH_GC_state.listRealLength * sizeof(BAH_GC_ptr)
    BAH_GC_state.list = malloc(s)
    memset(BAH_GC_state.list, 0, s)

    // BAH_GC_state.scanChannel = BAH_GC_channel{}

    // i=0; for i < 4, i++ {
    //     st = <BAH_GC_thread*>malloc(sizeof(BAH_GC_thread))
    //     pthread_create(&st.t, null, GC_thread_worker, null)
    //     st.next = BAH_GC_state.scanThreads
    //     BAH_GC_state.scanThreads = st
    // }
}

#init GC_setStackBase()
#init GC_init()


GC_markPtr(p uint) {
    if p == 0 {
        return
    }

    if BAH_GC_state.isPointerInBounds(p) == false || p == <uint>BAH_GC_state.list {
        return
    }

    gcPtr = BAH_GC_state.find(p)

    if gcPtr == null {
        return
    }

    if gcPtr.marked {
        return
    }

    gcPtr.marked = true

    if gcPtr.notScannable == false {
        if BAH_GC_state.stackBase - <uint>$rbp >= 6000000 {
            overflowNode = <BAH_GC_channelNode*>malloc(sizeof(BAH_GC_channelNode))
            overflowNode.data = gcPtr
            overflowNode.next = BAH_GC_state.overflowQueue
            BAH_GC_state.overflowQueue = overflowNode
            return
        }
        GC_scan(p, p + gcPtr.size - 7, 1)
    }
}


GC_scan(from uint, to uint, alignment uint) {
    p = from
    if from > to || to - from < alignment {
        return
    }
    // printInt(to - from)
    for p < to, p = p + alignment {
        content = *<uint*>p
        GC_markPtr(content)
    }
}

GC_scanReversed(from uint, to uint, alignment uint) {
    p = from
    if from < to || from - to < alignment {
        return
    }
    for p > to, p = p - alignment {
        content = *<uint*>p

        GC_markPtr(content)
    }
}

GC_stopWorld() {
    t = BAH_GC_state.threads
    callerId = syscall(__NR_gettid)
    for t != null, t = t.next {
        if t.sysid == callerId {
            continue
        }
        sigqueue(t.sysid, SIGXCPU, null)
    }
}

// GC_thread_worker() {
//     for 1==1 {
//         gcPtr = BAH_GC_state.scanChannel.receive()
//         GC_scan(gcPtr.p, gcPtr.p + gcPtr.size - 7, 1)
//     }
// }

GC_collect() {
    //save registers
    ordi = <uint>$rdi
    orsi = <uint>$rsi
    ordx = <uint>$rdx
    orcx = <uint>$rcx
    or8 = <uint>$r8
    or9 = <uint>$r9
    or10 = <uint>$r10
    orax = <uint>$rax
    orbx = <uint>$rbx

    currBasePointer = <uint>$rbp + 8

    if syscall(__NR_gettid) != BAH_GC_state.mainThread {
        //TODO: siqueue main thread and call collect there
        return  //only the main thread can pause the world
    }

    GC_stopWorld()

    qsort(BAH_GC_state.list, BAH_GC_state.listRealLength, sizeof(BAH_GC_ptr), GC_sort_pointers)

    // puts("stack:")



    //check registers
    GC_markPtr(ordi)
    GC_markPtr(orsi)
    GC_markPtr(ordx)
    GC_markPtr(orcx)
    GC_markPtr(or8)
    GC_markPtr(or9)
    GC_markPtr(or10)
    GC_markPtr(orax)
    GC_markPtr(orbx)

    //check .data and .bss
    dataStart = <uint>$data
    bssStart = <uint>$bss
    bssEnd = <uint>$end

    GC_scan(dataStart, bssStart, 1)
    GC_scan(bssStart, bssEnd, 1)

    //check stack
    GC_scanReversed(BAH_GC_state.stackBase, currBasePointer, 8)

    // puts("(threads)")
    //scan threads stacks
    ct = BAH_GC_state.threads
    for ct != null, ct = ct.next {    
        s uint = 0
        addr uint = 0
        attr pthread_attr_t
        pthread_getattr_np(ct.t, &attr)
        pthread_attr_getstack(&attr, &addr, &s)
        pthread_attr_destroy(&attr)
        GC_scanReversed(<uint>addr + s - 8, addr, 8)
    }

    freed=0
    alive=0

    additional=0
    for BAH_GC_state.overflowQueue != null {
        currQueue = BAH_GC_state.overflowQueue
        BAH_GC_state.overflowQueue = null
        for currQueue != null {
            GC_scan(currQueue.data.p, currQueue.data.p + currQueue.data.size - 7, 1)
            prevQueue = currQueue
            currQueue = currQueue.next
            free(prevQueue)
            additional++
        }
    }

    l = BAH_GC_state.listLength
    i=0; for i < l, i++ {
        index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
        if index.p == 0 {
            continue
        }

        if index.marked == false {
            freed++
            free(<ptr>index.p)
            index.p = 0
            BAH_GC_state.heapSize -= index.size
            BAH_GC_state.listLength--
            continue
        }
        alive++

        index.marked = false
    }

    qsort(BAH_GC_state.list, BAH_GC_state.listRealLength, sizeof(BAH_GC_ptr), GC_sort_pointers)


    // return
    // puts("freed: ")
    // printInt(freed)
    // puts("still allive: ")
    // printInt(alive)
    // puts("heap size:")
    // printInt(BAH_GC_state.heapSize)
}

memoryAlloc(s uint) ptr {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, false)
    memset(<ptr>r, 0, s)

    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}

memoryRealloc(o ptr, s uint) ptr {
    if o == null {
        return memoryAlloc(s)
    }

    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }

    

    r = <uint>realloc(o, s)

    if r == 0 {
        panic("GC: could not reallocate memory.")
    }

    index BAH_GC_ptr*
    i = BAH_GC_state.listLength
    for i < BAH_GC_state.listRealLength, i++ {
        index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
        if index.p == <uint>o {
            break
        }
    }

    if i == BAH_GC_state.listRealLength {
        i = BAH_GC_state.listLength-1
        for i != -1, i-- {
            index = <BAH_GC_ptr*>(<uint>BAH_GC_state.list + i * sizeof(BAH_GC_ptr))
            if index.p == <uint>o {
                break
            }
        }
    }

    if i == -1 {
        panic("GC: fatal error doing reallocation")
    }

    memset(<ptr>(<uint>r + index.size), 0, s - index.size)

    BAH_GC_state.heapSize += s - index.size
    index.size = s

    if r != <uint>o {
        index.p = r
        BAH_GC_state.updatePagesBounds(r)
    }

    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}


memoryAllocSTR(s uint) str {
    pthread_mutex_lock(BAH_GC_state.mut)
    if BAH_GC_state.heapSize >= BAH_GC_state.nextCollect {
        GC_collect()
        BAH_GC_state.nextCollect = BAH_GC_state.heapSize * 2
        if BAH_GC_state.nextCollect < GC_min_collect {
            BAH_GC_state.nextCollect = GC_min_collect
        }
    }


    r = BAH_GC_state.allocate(s, true)
    memset(<ptr>r, 0, s)
    pthread_mutex_unlock(BAH_GC_state.mut)
    return <ptr>r
}